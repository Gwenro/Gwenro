---
title: "FinalProject_Rockoff_Benjamin"
author: "Benjamin Rockoff"
date: "8/18/2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Data Preperation

## a. Load the dataset insurance.csv into memory.

```{r}
insurance <- read.csv("C:/Users/ben/Downloads/insurance.csv")

insurance$sex <- as.factor(insurance$sex)
insurance$smoker <- as.factor(insurance$smoker)
insurance$region <- as.factor(insurance$region)
```

## b. In the data frame, transform the variable charges by setting insurance$charges = log(insurance$charges). Do not transform it outside of the data frame.

```{r}
insurance$charges <- log(insurance$charges)
```

## c.Using the data set from 1.b, use the model.matrix() function to create another data set that uses dummy variables in place of categorical variables. Verify that the first column only has ones (1) as values, and then discard the column only after verifying it has only ones as values.

```{r}
dummy.insurance <- as.data.frame(model.matrix(~., data = insurance))
dummy.insurance = dummy.insurance[,-1]
```

## d. Use the sample() function with set.seed equal to 1 to generate row indexes for your training and tests sets, with 2/3 of the row indexes for your training set and 1/3 for your test set. Do not use any method other than the sample() function for splitting your data.

```{r}
set.seed(1)
train.index <- sample(1:nrow(insurance), 2*(nrow(insurance)/3))
test.index <- (1:nrow(insurance))[-train.index]
```

## e. Create a training and test data set from the data set created in 1.b using the training and test row indexes created in 1.d. Unless otherwise stated, only use the training and test data sets created in this step.

```{r}
train <- insurance[train.index,]
test <- insurance[test.index,]
```

## f. Create a training and test data set from data set created in 1.c using the training and test row indexes created in 1.d

```{r}
train.dummy <- dummy.insurance[train.index,]
test.dummy <- dummy.insurance[test.index,]
```

# 2. Build a multiple linear regression model.

## a. Perform multiple linear regression with charges as the response and the predictors are age, sex, bmi, children, smoker, and region. Print out the results using the summary() function. Use the training data set created in step 1.e to train your model.

```{r}
lm.train <- lm(charges ~age + sex + bmi + children + smoker + region, data = train)
```

## b. Is there a relationship between the predictors and the response?

```{r}
summary(lm.train)
```

Yes there is a relationship between the predictors and the response. This is denoted by a p-value of 2.2e-16 which is less than .05%.

## c. Does sex have a statistically significant relationship to the response?

No the sexmale variable is not statistically significant as it has a p-value of .11884 which is more than .05%

## d. Perform best subset selection using the stepAIC() function from the MASS library, choose best model based on AIC. For the "direction" parameter in the stepAIC() method, set direciton="backward"

```{r}
library(MASS)
lm.bwd <- stepAIC(lm.train, direction = "backward")
```

## e. Compute the test error of the best model in 2d based on AIC using LOOCV using trainControl() and train() from the caret library. Report the MSE by squaring the reported RMSE.

```{r}
library(caret)
train_control <- trainControl(method="LOOCV")
model.LOOCV <- train(charges ~ age + sex + bmi + children + smoker + region, data = insurance, trControl=train_control, method="lm")
LOOCV_model <- summary(model.LOOCV)
LOOCV.MSE <- mean(LOOCV_model$residuals^2)
LOOCV.MSE
```
The MSE is .1960605

## f. Calculate the test error of the best model in 2d based on AIC using 10-fold Cross-Validation. Use train and trainControl from the caret library. Refer to model selected in 2d based on AIC. Report the MSE.

```{r}
train_control <- trainControl(method="CV", number=10)
model.10CV <- train(charges ~ age + sex + bmi + children + smoker + region, data = insurance, trControl=train_control, method="lm")
tenfcv <- summary(model.10CV)
tenfcv.MSE <-  mean(tenfcv$residuals^2)
tenfcv.MSE
```
The MSE is .1960605

## g. Calculate and report the test MSE using the best model from 2.d and the test data set from step 1.e.

```{r}
lm.test <- lm(charges ~ age + sex + bmi + children + smoker + region, data = test)
test.lm <- summary(lm.test)
lm.MSE <- mean(test.lm$residuals^2)
lm.MSE
```
The test MSE is .2082312

## h. Compare the test MSE calculated in step 2.f using 10-fold cross-validation with the test MSE calculated in step 2.g. How similar are they?

```{r}
lm.MSE - tenfcv.MSE
```
There is a difference of .01217072 between the test 10-fold CV MSE and the test data set MSE.

# 3. Build a regression tree model.

```{r}
library(tree)
```

## a. Build a regression tree model using function tree(), where charges is the response and the predictors are age, sex, bmi, children, smoker, and region.

```{r}
tree.insurance <- tree(charges ~ age + sex + bmi + children + smoker + region, train)
```

## b. Find the optimal tree by using cross-validation and display the results in a graphic. Report the best size.

```{r}
cv.insurance <- cv.tree(tree.insurance)
plot(cv.insurance$size, cv.insurance$dev, type='b')
```

## c. Justify the number you picked for the optimal tree with regard to the principle of variance-bias trade-off.

The number I picked for the optimal tree is 3 because it is a simple model and is the beginning of a downward trend in test error.

## d. Prune the tree using the optinal size found in 3.b

```{r}
prune.insurance <- prune.tree(tree.insurance, best = 3)
```

## e. Plot the best tree model and give labels.

```{r}
plot(prune.insurance)
text(prune.insurance, pretty = 0)
```

## f. Calculate the test MSE for the best model.

```{r}
yhat <- predict(prune.insurance, newdata = test)
insurance.test <- insurance[-train.index, "charges"]
tree.MSE <- mean((yhat-insurance.test)^2)
tree.MSE
```
The test error is .2771888

# 4. Build a random forest model.

```{r}
library(randomForest)
```

## a. Build a random forest model using function randomForest(), where charges is the response and the predictors are age, sex, bmi, children, smoker, and region.

```{r}
rf.insurance <- randomForest(charges ~ age + sex + bmi + children + smoker + region, data = train, importance = TRUE)
```

## b. Compute the test error using the test data set.

```{r}
yhat.rf <- predict(rf.insurance, newdata = test)
rf.MSE <- mean((yhat.rf-insurance.test)^2)
rf.MSE
```
The test error is .171809

## c. Extract variable importance measure using the importance() function.

```{r}
importance(rf.insurance)
```

## d. Plot the variable importance using the function, varImpPlot(). Which are the top 3 important predictors in this model?

```{r}
varImpPlot(rf.insurance)
```

The top 3 important predictors in this model are smoker, age, and children for %IncMSE and smoker, age, and BMI for IncNodePurity.

# 5. Build a support vector machine model.

```{r}
library(e1071)
```

## a. The response is charges and the predictors are age, sex, bmi, children, smoker, and region. Please use the svm() function with radial kernel and gamma=5 and cost = 50.

```{r}
svm.fit <- svm(charges ~ age + sex + bmi + children + smoker + region, data = train, kernel = "radial", gamma = 5, cost = 50)
summary(svm.fit)
```

## b. Perform a grid search to find the best model with potential cost: 1, 10, 50, 100 and potential gamma: 1,3 and 5 and potential kernel: "linear","polynomial","radial" and "sigmoid". And use the training set created in step 1.e.

```{r}
tune.out <- tune(svm, charges ~ age + sex + bmi + children + smoker + region, data = train, kernel = "radial", ranges = list(cost = c(1,10,50,100), gamma = c(1,3,5)))
```

## c. Print out the model results. What are the best model parameters?

```{r}
summary(tune.out)
```

## d. Forecast charges using the test dataset and the best model found in c).

```{r}
pred <- predict(tune.out$best.model, newdata = test)
```

## e. Compute the MSE (Mean Squared Error) on the test data.

```{r}
svm.MSE <- mean((yhat.rf-insurance.test)^2)
svm.MSE
```
The MSE is .171809

# 6. Perform the k-means cluster analysis.

```{r}
library(cluster)
library(factoextra)
```

## a. Use the training data set created in step 1.f and standardize the inputs using the scale() function.

```{r}
std.dummy <- scale(train.dummy)
```

## b. Convert the standardized inputs to a data frame using the as.data.frame() function.

```{r}
df.dummy <- as.data.frame(std.dummy)
```

## c. Determine the optimal number of clusters, and use the gap_stat method and set iter.max=20. Justify your answer. It may take longer running time since it uses a large dataset.

```{r}
insurance_kmc <- fviz_nbclust(df.dummy, kmeans, method = "gap_stat", iter.max = 20)
insurance_kmc
```

## d. Perform k-means clustering using the optimal number of clusters found in step 6.c. Set parameter nstart = 25

```{r}
km.res <- kmeans(df.dummy, 5, nstart = 25)
```

## e. Visualize the clusters in different colors, setting parameter geom="point"

```{r}
fviz_cluster(km.res, data = df.dummy, geom="point")
```

# 7. Build a neural networks model.

```{r}
library(neuralnet)
```

## a. Using the training data set created in step 1.f, create a neural network model where the response is charges and the predictors are age, sexmale, bmi, children, smokeryes, regionnorthwest, regionsoutheast, and regionsouthwest. Please use 1 hidden layer with 1 neuron. Do not scale the data.

```{r}
nn.model <- neuralnet(charges ~ age + sexmale + bmi + children + smokeryes + regionnorthwest + regionsoutheast + regionsouthwest, data = train.dummy, hidden = c(1,1))
```

## b. Plot the neural network.

```{r}
plot(nn.model, rep = "best")
```

## c. Forecast the charges in the test dataset.

```{r}
predict.nn <- compute(nn.model, test.dummy[, c("age", "sexmale", "bmi", "children", "smokeryes", "regionnorthwest", "regionsoutheast", "regionsouthwest")])
```

## d. Compute test error (MSE).

```{r}
dummy.test <- test.dummy$charges
neural.MSE <- mean((dummy.test-predict.nn$net.result)^2)
neural.MSE
```

The test error is .8357085

# 8. Putting it all together.

## a. For predicting insurance charges, your supervisor asks you to choose the best model among the multiple regression, regression tree, random forest, support vector machine, and neural network models. Compare the test MSEs of the models generated in steps 2.g, 3.f, 4.b, 5.e, and 7.d. Display the names for these types of these models, using these labels: "Multiple Linear Regression", "Regression Tree", "Random Forest", "Support Vector Machine", and "Neural Network" and their corresponding test MSEs in a data.frame. Label the column in your data frame with the labels as "Model.Type", and label the column with the test MSEs as "Test.MSE" and round the data in this column to 4 decimal places. Present the formatted data to your supervisor and recommend which model is best and why.

```{r}
Model.Type = c("Multiple Linear Regression", "Regression Tree", "Random Forest", "Support Vector Machine", "Neural Network")

Test.MSEs <- round(c(lm.MSE, tree.MSE, rf.MSE, svm.MSE, neural.MSE),4)

best.MSE <- data.frame(Model.Type, Test.MSEs)
```

I would recommend the support vector machine model over multiple linear regression due to its low test error of .1718. I would recommend it over the random forest model due to its increased interpretability. Finally I would recommend the support vector machine model due to it being a model in a data set of under 1000 observations; support vector machines run faster with less data.

## b. Another supervisor from the sales department has requested your help to create a predictive model that his sales representatives can use to explain to clients what the potential costs could be for different kinds of customers, and they need an easy and visual way of explaining it. What model would you recommend, and what are the benefits and disadvantages of your recommended model compared to other models?

I would recommend the regression tree model for its ease in explaining costs in relation to other variables. Regression tree models also work well with large data sets, and are able to use both numerical and categorical data. The disadvantages of regression trees are: 
-Are very temperamental a small shift could cause a large change.
-Need to cross validate to find the right number of branches for tree; to combat overfitting.

## c. The supervisor from the sales department likes your regression tree model. But she says that the sales people say the numbers in it are way too low and suggests that maybe the numbers on the leaf nodes predicting charges are log transformations of the actual charges. You realize that in step 1.b of this project that you had indeed transformed charges using the log function. And now you realize that you need to reverse the transformation in your final output. The solution you have is to reverse the log transformation of the variables in the regression tree model you created and redisplay the result. Follow these steps:

### i. Copy your pruned tree model to a new variable.

```{r}
prune.insurance2 <- prune.insurance 
```

### ii. In your new variable, find the data.frame named "frame" and reverse the log transformation on the data.frame column yval using the exp() function. (If the copy of your pruned tree model is named copy_of_my_pruned_tree, then the data frame is accessed as copy_of_my_pruned_tree$frame, and it works just like a normal data frame.).

```{r}
prune.insurance2$frame[,"yval"]<- exp(prune.insurance2$frame[,"yval"])
```

### iii. After you reverse the log transform on the yval column, then replot the tree with labels.

```{r}
plot(prune.insurance2)
text(prune.insurance2, pretty = 0)
```
